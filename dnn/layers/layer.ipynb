{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ActivationLayer(Layer):\\n    \"\"\"Implements layer which convert values by activation function.\\n\\n    Parameters\\n    ----------\\n    activation : Derived class of Activation\\n        Activation function to use.\\n    shape : tuple\\n        Shape of this layer\\'s neurons.\\n    \"\"\"\\n    def __init__(self, activation):\\n        \"\"\"\\n        Arguments\\n        ---------\\n        activation : Activation.Type\\n           Name of activation function to use.\\n        \"\"\"\\n        self.activation = ActivationFactory.get(activation)\\n\\n    def get_type(self):\\n        return \\'activation\\'\\n\\n    def set_parent(self, parent):\\n        Layer.set_parent(self, parent)\\n        self.shape = parent.shape\\n\\n    def forward(self, x):\\n        self.fire = self.activation.activate(x)\\n        self.child.forward(self.fire)\\n\\n    def backward(self, dy):\\n        self.backfire = dy * self.activation.grad(self.fire)\\n        self.parent.backward(self.backfire)\\n\\n    def predict_to_eval(self, x):\\n        self.fire = self.activation.activate(x)\\n        return self.child.predict_to_eval(self.fire)\\n\\n    def predict(self, x):\\n        self.fire = self.activation.activate(x)\\n        return self.child.predict(self.fire)\\n\\n    def finalize_training(self, x):\\n        self.fire = self.activation.activate(x)\\n        self.child.finalize_training(self.fire)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authors: Daichi Yoshikawa <daichi.yoshikawa@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"Base class for layers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dtype : type\n",
    "        Data type to use.\n",
    "    fire : np.array\n",
    "        Result of forward calculation in this layer.\n",
    "    backfire : np.array\n",
    "        Result of backward calculation in this layer.\n",
    "    parent : Derived class of Layer\n",
    "        Parent layer of this layer.\n",
    "    child : Derived class of Layer\n",
    "        Child layer of this layer.\n",
    "    input_shape : int or tuple\n",
    "        Number of neurons of parent's layer.\n",
    "    output_shape : int or tuple\n",
    "        Number of neurons of this layer.\n",
    "\n",
    "    Warning\n",
    "    -------\n",
    "    This class should not be used directly.\n",
    "    Use derived classes instead.\n",
    "    \"\"\"\n",
    "    dtype = np.float64\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "        self.output_shape = None\n",
    "        self.fire = None\n",
    "        self.backfire = None\n",
    "\n",
    "    def set_dtype(self, dtype):\n",
    "        pass\n",
    "\n",
    "    def get_type(self):\n",
    "        raise NotImplementedError('Layer.get_type')\n",
    "\n",
    "    def has_weight(self):\n",
    "        return False\n",
    "\n",
    "    def set_parent(self, parent):\n",
    "        \"\"\"Set parent layer to this layer and\n",
    "        set this layer to parent layer's child layer.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        parent : Derived class of Layer\n",
    "            Any reasonable layer.\n",
    "        \"\"\"\n",
    "        self.parent = parent\n",
    "        parent.child = self\n",
    "\n",
    "        self.input_shape = parent.output_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward calculation called in training phase.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array\n",
    "            fire of parent layer in 2d array.\n",
    "            If no parent layer, it would be normalized descriptive features.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Layer.forward')\n",
    "\n",
    "    def backward(self, dy):\n",
    "        \"\"\"Backward calculation.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        dy : np.array\n",
    "            backfire of child layer in 2d array.\n",
    "            If no child layer, it would be errors of\n",
    "            current predicted results against training data.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Layer.backward')\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Forward calculation called in prediction phase.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array\n",
    "            fire of parent layer in 2d array.\n",
    "            If no parent layer, it would be normalized descriptive features.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Layer.predict')\n",
    "\n",
    "    def finalize_training(self, x):\n",
    "        \"\"\"Implements finalizing training of layer.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array\n",
    "            fire of parent layer in 2d array.\n",
    "            If no parent layer, it would be normalized descriptive features.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError('Layer.finalize')\n",
    "\n",
    "\n",
    "class InputLayer(Layer):\n",
    "    \"\"\"Implement the first layer of neural network.\n",
    "\n",
    "    Derived class of Layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = self.input_shape\n",
    "\n",
    "    def get_type(self):\n",
    "        return 'input'\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Starting point of forward calculation.\"\"\"\n",
    "        self.child.forward(x)\n",
    "\n",
    "    def backward(self, dy):\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.child.predict(x)\n",
    "\n",
    "    def finalize_training(self, x):\n",
    "        self.child.finalize_training(x)\n",
    "\n",
    "\n",
    "class OutputLayer(Layer):\n",
    "    \"\"\"Implements the last layer of neural network.\n",
    "\n",
    "    Derived class of Layer.\n",
    "    \"\"\"\n",
    "    def get_type(self):\n",
    "        return 'output'\n",
    "\n",
    "    def set_parent(self, parent):\n",
    "        Layer.set_parent(self, parent)\n",
    "        self.output_shape = self.input_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.fire = x\n",
    "\n",
    "    def backward(self, dy):\n",
    "        \"\"\"Starting point of backward calculation.\"\"\"\n",
    "        self.backfire = dy\n",
    "        self.parent.backward(self.backfire)\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.fire = x\n",
    "        return self.fire\n",
    "\n",
    "    def finalize_training(self, x):\n",
    "        self.fire = x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
