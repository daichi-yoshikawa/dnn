{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authors: Daichi Yoshikawa <daichi.yoshikawa@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from .utils.nn_utils import get_kwarg, shuffle_data, split_data, w2im\n",
    "from .utils.nn_utils import is_multi_channels_image, flatten, unflatten\n",
    "from .training.random_weight import RandomWeight\n",
    "from .training.back_propagation import BackPropagation\n",
    "from .layers.layer import Layer, InputLayer, OutputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"Interface of neural network.\n",
    "\n",
    "    Training of model and prediction with resulting model\n",
    "    is done through this class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    layers : np.array of derived class of Layer\n",
    "        Layers to build neural network.\n",
    "        The first layer must be InputLayer and last layer must be OutputLayer.\n",
    "    dtype : type\n",
    "        Data type selected through constructor.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def load(self, name, path=None):\n",
    "        \"\"\"Load model from storage.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        name : str or None, default None\n",
    "            Name of the desired file. Doesn't include path.\n",
    "        path : str or None, default None\n",
    "            Full path to the directory where the desired file is contained.\n",
    "            If None, file is loaded from a directory where script runs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        NeuralNetwork\n",
    "            Returns model.\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = '.'\n",
    "        if path[0] == '~':\n",
    "            path = os.getenv(\"HOME\") + path[1:]\n",
    "\n",
    "        try:\n",
    "            with open(path + '/' + name, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except IOError as e:\n",
    "            msg = str(e) + '\\nNeuralNetwork.load failed.'\n",
    "            print(msg)\n",
    "\n",
    "    def __init__(self, input_shape, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        dtype : type, default np.float32\n",
    "            Data type to use.\n",
    "        \"\"\"\n",
    "        self.layers = np.array([], dtype=Layer)\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    def add(self, layer):\n",
    "        \"\"\"Add instance of derived class of layer.\n",
    "\n",
    "        Build neural network by adding layers one by one with this method.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layer : Derived class of Layer\n",
    "            Instance of derived class of Layer.\n",
    "        \"\"\"\n",
    "        layer.set_dtype(self.dtype)\n",
    "        self.layers = np.append(self.layers, layer)\n",
    "\n",
    "    def compile(self):\n",
    "        \"\"\"Finalize configuration of neural network model.\n",
    "\n",
    "        Warning\n",
    "        -------\n",
    "        This method must be called after adding all required layers\n",
    "        and before starting training.\n",
    "        \"\"\"\n",
    "        if self.layers.size == 0:\n",
    "            msg = 'NeuralNetwork has no layer.\\n'\\\n",
    "                + 'Please add layers before compiling.'\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "        parent = self.layers[0]\n",
    "\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            layer.set_parent(parent)\n",
    "            parent = layer\n",
    "\n",
    "        output_layer = OutputLayer()\n",
    "        output_layer.set_parent(self.layers[-1])\n",
    "        self.add(output_layer)\n",
    "\n",
    "    def fit(self, x, y, optimizer, loss_function, **kwargs):\n",
    "        \"\"\"Train model.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array\n",
    "            Descriptive features in 2d array,\n",
    "            whose shape is (num of data, num of feature)\n",
    "        y : np.array\n",
    "            Target features in 2d array,\n",
    "            whose shape is (num of data, num of feature)\n",
    "        optimizer : Derived class of Optimizer\n",
    "            Instance of derived class of Optimizer.\n",
    "        loss_function : LossFunction.Type\n",
    "            Type of loss function to use.\n",
    "        epochs : int, default 10\n",
    "            Number of iterations of training.\n",
    "            1 iteration scans all batches one time.\n",
    "        batch_size : int, default 100\n",
    "            Dataset is splitted into multiple mini batches\n",
    "            whose size is this.\n",
    "        learning_curve : bool, default True\n",
    "            Prints out evaluation results of ongoing training.\n",
    "            Also, returns learning curve after completion of training.\n",
    "        shuffle : bool, default True\n",
    "            Shuffle dataset one time before training.\n",
    "        shuffle_per_epoch : bool, default False\n",
    "            Shuffle training data every epoch.\n",
    "        test_data_ratio : float, default 0\n",
    "            Ratio of test data. If 0, all data is used for training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        LearningCurve\n",
    "            Instance of LearningCurve, which contains\n",
    "            losses and accuracies for train and test data.\n",
    "\n",
    "        Warning\n",
    "        -------\n",
    "        This method assumes that x and y include all data you use.\n",
    "        If your data set is so large that all data cannot be stored in memory,\n",
    "        you cannot use this method. Use fit_genenerator instead.\n",
    "        \"\"\"\n",
    "        epochs = get_kwarg(\n",
    "                key='epochs',\n",
    "                dtype=int,\n",
    "                default_value=10,\n",
    "                **kwargs)\n",
    "        batch_size = get_kwarg(\n",
    "                key='batch_size',\n",
    "                dtype=int,\n",
    "                default_value=100,\n",
    "                **kwargs)\n",
    "        learning_curve = get_kwarg(\n",
    "                key='learning_curve',\n",
    "                dtype=bool,\n",
    "                default_value=True,\n",
    "                **kwargs)\n",
    "        shuffle = get_kwarg(\n",
    "                key='shuffle',\n",
    "                dtype=bool,\n",
    "                default_value=True,\n",
    "                **kwargs)\n",
    "        shuffle_per_epoch = get_kwarg(\n",
    "                key='shuffle_per_epoch',\n",
    "                dtype=bool,\n",
    "                default_value=False,\n",
    "                **kwargs)\n",
    "        test_data_ratio = get_kwarg(\n",
    "                key='test_data_ratio',\n",
    "                dtype=self.dtype,\n",
    "                default_value=self.dtype(0.),\n",
    "                **kwargs)\n",
    "\n",
    "        if shuffle:\n",
    "            x, y = shuffle_data(x, y)\n",
    "        x, y = self.__convert_dtype(x, y)\n",
    "        x_train, y_train, x_test, y_test = split_data(x, y, test_data_ratio)\n",
    "\n",
    "        back_prop = BackPropagation(\n",
    "                epochs,\n",
    "                batch_size,\n",
    "                optimizer,\n",
    "                loss_function,\n",
    "                learning_curve,\n",
    "                self.dtype\n",
    "        )\n",
    "        lc = back_prop.fit(self.layers, x_train, y_train, x_test, y_test, shuffle_per_epoch)\n",
    "\n",
    "        return lc\n",
    "\n",
    "    def fit_generator(self, x, y, optimizer, loss_function, **kwargs):\n",
    "        \"\"\"Train model for large size data set by using generator.\n",
    "        TODO\n",
    "        \"\"\"\n",
    "        raise NotImplementError('NeuralNetwork.fit_one_batch')\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Returns predicted result.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array\n",
    "            Discriptive features in 2d array,\n",
    "            whose shape is (num of data, num of features)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Predicted target features in 2d array,\n",
    "            whose shape is (num of data, num of features)\n",
    "        \"\"\"\n",
    "        return self.layers[0].predict(x.astype(self.dtype))\n",
    "\n",
    "    def print_config(self):\n",
    "        \"\"\"Display configuration of layers.\"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(('%2d-th layer, (input_shape, output_shape) : '\\\n",
    "                    + str((layer.input_shape, layer.output_shape))\\\n",
    "                    + ', ' + layer.get_type()) % (i))\n",
    "\n",
    "    def save(self, name, path=None):\n",
    "        \"\"\"Save model to storage.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        name : str or None, default None\n",
    "            Name of the resulting file. Doesn't include path.\n",
    "        path : str or None, default None\n",
    "            Full path to the directory where the resulting file is generated.\n",
    "            If None, file is saved in a directory where script runs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            Returns true when succeeded.\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = '.'\n",
    "        if path[0] == '~':\n",
    "            path = os.getenv(\"HOME\") + path[1:]\n",
    "\n",
    "        try:\n",
    "            with open(path + '/' + name, 'wb') as f:\n",
    "                pickle.dump(self, f)\n",
    "        except IOError as e:\n",
    "            msg = str(e) + '\\nNeuralNetwork.save failed.'\n",
    "            print(msg)\n",
    "\n",
    "    def show_filters(self, index, shape, layout, figsize=(8, 8)):\n",
    "        \"\"\"Visualize filters.\n",
    "\n",
    "        Weight matrix in affine layer or convolution layer\n",
    "        can be shown as image.\n",
    "        If weight matrix is so big that all filters cannot be displayed,\n",
    "        displayed filters are randomly selected.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            index-th affine/convolution layer's weight matrix is visualized.\n",
    "            This index starts from 0, that is, the first layer with weight matrix is 0-th.\n",
    "            If this value is out of range, raise RuntimeError.\n",
    "        shape : tuple (rows, cols)\n",
    "            Shape of filter. In the case of multi-channel,\n",
    "            filters are taken as single channel by taking average over channels.\n",
    "        layout : tuple (rows, cols)\n",
    "            Number of filter to display in direction of rows and cols respectively.\n",
    "        \"\"\"\n",
    "        # Get index of layer which is index-th layer with weight matrix.\n",
    "        num_of_layer_with_filter = 0\n",
    "        tgt_index = None\n",
    "\n",
    "        for i, layer in enumerate(self.layers, 0):\n",
    "            if layer.has_weight():\n",
    "                if num_of_layer_with_filter == index:\n",
    "                    tgt_index = i\n",
    "                    break\n",
    "                num_of_layer_with_filter += 1\n",
    "\n",
    "        if tgt_index is None:\n",
    "            msg = str(index) + '-th layer with weight matrix doesn\\'t exist.'\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "        img = w2im(self.layers[tgt_index].w, shape, layout)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    def __convert_dtype(self, x, y):\n",
    "        \"\"\"Convert data type of features into selected one in constructor.\"\"\"\n",
    "        return x.astype(self.dtype), y.astype(self.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
