{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authors: Daichi Yoshikawa <daichi.yoshikawa@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# This file is going to be merged with nn_utils module.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pad_img(img, pad_rows, pad_cols):\n",
    "    \"\"\"Returns padded matrix which represents image.\n",
    "\n",
    "    1d matrix is not supported.\n",
    "    Shape must be in forms of (***, ***, ... , ***, rows, cols),\n",
    "    such as (rows, cols), (channels, rows, cols),\n",
    "    or (batch size, channels, rows, cols), etc.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    img : np.array\n",
    "        Image matrix in 2 or more dimensional array.\n",
    "        This array is not exposed to side effect.\n",
    "    pad_rows : int or tuple (pad_upper, pad_lower)\n",
    "        Number of pad in direction of rows.\n",
    "        If tuple, the first entry is a number of pad in upper side\n",
    "        and the second one is that in lower side.\n",
    "    pad_cols : int or tuple (pad_left, pad_right)\n",
    "        Number of pad in direction of cols.\n",
    "        If tuple, the first entry is a number of pad in left side\n",
    "        and the second one is that in right side.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The resulting matrix, that is, padded matrix.\n",
    "    \"\"\"\n",
    "    if (img.ndim < 2):\n",
    "        msg = '1d array is not supported.'\n",
    "        raise RuntimeError(msg)\n",
    "\n",
    "    if np.prod(pad) == 0:\n",
    "        return img\n",
    "\n",
    "    npad = ()\n",
    "    for i in range(img.ndim - 2):\n",
    "        npad = npad + ((0, 0),)\n",
    "\n",
    "    if isinstance(pad_rows, tuple):\n",
    "        npad = npad + ((pad_rows[0], pad_rows[1]),)\n",
    "    else:\n",
    "        npad = npad + ((pad_rows, pad_rows),)\n",
    "\n",
    "    if isinstance(pad_cols, tuple):\n",
    "        npad = npad + ((pad_cols[0], pad_cols[1]),)\n",
    "    elif pad_cols:\n",
    "        npad = npad + ((pad_cols, pad_cols),)\n",
    "\n",
    "    return np.pad(img, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_img(img):\n",
    "    \"\"\"Returns reshaped 4d matrix.\n",
    "\n",
    "    im2col function assumes that input matrix is 4d (bathes, channels, rows, cols).\n",
    "    This function helps im2col by reshaping the matrix properly.\n",
    "    If matrix's dimension is more than 4, this throws exception.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    img : np.array\n",
    "        Matrix in 1-4d array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Matrix in 4d array.\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 1:\n",
    "        return img.reshape(1, 1, 1, img.shape[0])\n",
    "    elif len(img.shape) == 2:\n",
    "        return img.reshape(1, 1, img.shape[0], img.shape[1])\n",
    "    elif len(img.shape) == 3:\n",
    "        return img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    elif len(img.shape) > 4:\n",
    "        msg = 'len(img.shape) must be <= 4.'\n",
    "        raise RuntimeError(msg)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_remainders_of_filtering(rows, cols, f_rows, f_cols, strides):\n",
    "    \"\"\"Get remainders which resulted from applying filter.\n",
    "\n",
    "    Combination of image size, filter size and stride size should be proper.\n",
    "    If it is improper, remainders appear when filtering, that is,\n",
    "    filter can't be applied to all pixels.\n",
    "    The resulting remainders can be used to detect applicability of filter,\n",
    "    or pad image to enable filtering.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    img \n",
    "    \"\"\"\n",
    "    rem_r = (rows - f_rows) % strides[0]\n",
    "    rem_c = (cols - f_cols) % strides[1]\n",
    "    return rem_r, rem_c\n",
    "\n",
    "\n",
    "def extend_img_for_filtering(img, rem_r, rem_c):\n",
    "    \"\"\"Extend(Pad) image matrix to enable it to be filtered properly.\n",
    "\n",
    "    Based on remainders of filtering, pad image with 0s.\n",
    "    This remainders are supposed to be gained through\n",
    "    get_remainders_of_filtering function.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    img : np.array\n",
    "        Matrix in 2-4d array, whose shape is (rows, cols), (channels, rows, cols),\n",
    "        or (batches, channels, rows, cols).\n",
    "    rem_r : int\n",
    "        Remainder in rows direction, which is derived from\n",
    "        get_remainders_of_filtering function.\n",
    "    rem_c : int\n",
    "        Remainder in cols direction, which is derived from\n",
    "        get_remainders_of_filtering function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Padded image in 2-4d array.\n",
    "    \"\"\"\n",
    "    pad_r = (gap_r//2, gap_r - (gap_r//2))\n",
    "    pad_c = (gap_c//2, gap_c - (gap_c//2))\n",
    "    return pad_img(img, pad_r, pad_c), pad_r, pad_c\n",
    "\n",
    "\n",
    "def im2col(img, f_shape, pad, strides, force=False):\n",
    "    \"\"\"Convert 2-4d image matrix into a form which is proper for convolution.\n",
    "\n",
    "    Convolutional neural network requires convolution and convolution requires\n",
    "    filtering to 2d images.\n",
    "    To do it with matrix computation, we have to convert original matrix,\n",
    "    whose shape would be (rows, cols), (channels, rows, cols)\n",
    "    or (batches, channels, rows, cols), into different form.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    img : np.array\n",
    "        Image matrix in 2-4d array, whose shape is (rows, cols),\n",
    "        (channels, rows, cols), or (batches, channels, rows, cols).\n",
    "    f_shape : tuple (num of filter, rows, cols)\n",
    "        Filter's shape.\n",
    "    pad : tuple (rows, cols)\n",
    "        Number of pad, which consists of 0s. If rows/cols shape is\n",
    "        tuple (upper/left, lower/right), you can specify number of pad\n",
    "        in upper/left or lower/right part of img.\n",
    "        Eg. \n",
    "        img : 1, 2, 3\n",
    "              4, 5, 6\n",
    "        In case of pad=(1, 1) :\n",
    "              0, 0, 0, 0, 0\n",
    "              0, 1, 2, 3, 0\n",
    "              0, 4, 5, 6, 0\n",
    "              0, 0, 0, 0, 0\n",
    "        In case of pad=((1, 2), (3, 2))\n",
    "              0, 0, 0, 0, 0, 0, 0, 0\n",
    "              0, 0, 0, 1, 2, 3, 0, 0\n",
    "              0, 0, 0, 4, 5, 6, 0, 0\n",
    "              0, 0, 0, 0, 0, 0, 0, 0\n",
    "              0, 0, 0, 0, 0, 0, 0, 0\n",
    "    strides : tuple (rows, cols)\n",
    "        Stride size of filter in rows and cols direction.\n",
    "    force : bool, default False\n",
    "        Force conversion by padding in case of that\n",
    "        combination of image shape, filter shape and strides is improper.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The resulting image matrix in 2d array.\n",
    "    \"\"\"\n",
    "    pimg = pad_img(reshape_img(img), pad[0], pad[1])\n",
    "\n",
    "    batches, chs, rows, cols = pimg.shape\n",
    "    _, f_rows, f_cols = f_shape\n",
    "    gap_r, gap_c = get_remainders_of_filtering(rows, cols, f_rows, f_cols, strides)\n",
    "\n",
    "    if (gap_r > 0) or (gap_c > 0):\n",
    "        if force:\n",
    "            pimg, ext_pad_r, ext_pad_r = extend_img_for_filtering(pimg, gap_r, gap_c)\n",
    "            batches, chs, rows, cols = pimg.shape\n",
    "        else:\n",
    "            msg = 'Filter cannot be applied to image with the strides.\\n'\\\n",
    "                + 'Image shape (with pad) : ' + str((rows, cols)) + '\\n'\\\n",
    "                + 'Filter shape : ' + str((f_rows, f_cols)) + '\\n'\\\n",
    "                + 'Strides : ' + str(strides)\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "    st_batch, st_ch, st_r, st_c = pimg.strides\n",
    "    f_st_r = st_r * strides[0]\n",
    "    f_st_c = st_c * strides[1]\n",
    "    dst_strides = (st_batch, st_ch, f_st_r, f_st_c, st_r, st_c)\n",
    "\n",
    "    dst_rows = (rows - f_rows) // strides[0] + 1\n",
    "    dst_cols = (cols - f_cols) // strides[1] + 1\n",
    "    dst_shape = (batches, chs, dst_rows, dst_cols, f_rows, f_cols)\n",
    "\n",
    "    dst_img = as_strided(pimg, shape=dst_shape, strides=dst_strides)\n",
    "    dst_rows = batches * dst_rows * dst_cols\n",
    "    dst_cols = chs * f_rows * f_cols\n",
    "    dst_img = dst_img.transpose(0, 2, 3, 1, 4, 5).reshape(dst_rows, dst_cols)\n",
    "\n",
    "    return dst_img\n",
    "\n",
    "\n",
    "def im2col_shape(img_shape, f_shape, pad, strides, force=False):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Shape (rows, cols) of the resulting matrix of im2col function.\n",
    "    \"\"\"\n",
    "    chs, rows, cols = img_shape\n",
    "    if isinstance(pad[0], tuple):\n",
    "        rows += np.sum(pad[0])\n",
    "    else:\n",
    "        rows += 2*pad[0]\n",
    "    if isinstance(pad[1], tuple):\n",
    "        cols += np.sum(pad[1])\n",
    "    else:\n",
    "        cols += 2*pad[1]\n",
    "\n",
    "    num_of_filter, f_rows, f_cols = f_shape\n",
    "    gap_r, gap_c = get_remainders_of_filtering(rows, cols, f_rows, f_cols, strides)\n",
    "\n",
    "    if (gap_r > 0) or (gap_c > 0):\n",
    "        if force:\n",
    "            pad_r = (gap_r//2, gap_r - (gap_r//2))\n",
    "            pad_c = (gap_c//2, gap_c - (gap_c//2))\n",
    "\n",
    "            rows += np.sum(pad_r)\n",
    "            cols += np.sum(pad_c)\n",
    "        else:\n",
    "            msg = 'Filter cannot be applied to image with the strides.\\n'\\\n",
    "                + 'Image shape (with pad) : ' + str((rows, cols)) + '\\n'\\\n",
    "                + 'Filter shape : ' + str((f_rows, f_cols)) + '\\n'\\\n",
    "                + 'Strides : ' + str(strides)\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "    dst_rows = (rows - f_rows) // strides[0] + 1\n",
    "    dst_cols = (cols - f_cols) // strides[1] + 1\n",
    "\n",
    "    return (dst_rows, dst_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "(48, 32) 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 32, 4, 4)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.arange(216).reshape(3, 2, 6, 6)\n",
    "f_shape = (32, 3, 3)\n",
    "#pad = (1, 1)\n",
    "pad = (0, 0)\n",
    "strides = (1, 1)\n",
    "force = True\n",
    "#print(img)\n",
    "col = im2col(img, f_shape, pad, strides, force)\n",
    "w_rows = 2 * 3 * 3\n",
    "w_cols = 32\n",
    "w = np.ones((w_rows, w_cols))\n",
    "\n",
    "batches, chs, rows, cols = img.shape\n",
    "rows, cols = im2col_shape(\n",
    "                (chs, rows, cols), f_shape, pad, strides, force)\n",
    "print(rows, cols)\n",
    "fire = np.dot(col, w)\n",
    "print(fire.shape, batches*rows*cols)\n",
    "fire = fire.reshape(batches, rows, cols, -1).transpose(0, 3, 1, 2)\n",
    "fire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]],\n",
       "\n",
       "        [[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]],\n",
       "\n",
       "        [[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]],\n",
       "\n",
       "        ..., \n",
       "        [[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]],\n",
       "\n",
       "        [[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]],\n",
       "\n",
       "        [[  450.,   468.,   486.,   504.],\n",
       "         [  558.,   576.,   594.,   612.],\n",
       "         [  666.,   684.,   702.,   720.],\n",
       "         [  774.,   792.,   810.,   828.]]],\n",
       "\n",
       "\n",
       "       [[[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]],\n",
       "\n",
       "        [[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]],\n",
       "\n",
       "        [[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]],\n",
       "\n",
       "        [[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]],\n",
       "\n",
       "        [[ 1746.,  1764.,  1782.,  1800.],\n",
       "         [ 1854.,  1872.,  1890.,  1908.],\n",
       "         [ 1962.,  1980.,  1998.,  2016.],\n",
       "         [ 2070.,  2088.,  2106.,  2124.]]],\n",
       "\n",
       "\n",
       "       [[[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]],\n",
       "\n",
       "        [[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]],\n",
       "\n",
       "        [[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]],\n",
       "\n",
       "        [[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]],\n",
       "\n",
       "        [[ 3042.,  3060.,  3078.,  3096.],\n",
       "         [ 3150.,  3168.,  3186.,  3204.],\n",
       "         [ 3258.,  3276.,  3294.,  3312.],\n",
       "         [ 3366.,  3384.,  3402.,  3420.]]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2im(mat, window_shape, batch_size, channels, h, w, strides=(1, 1), ch_axis=1):\n",
    "    win_h, win_w = window_shape\n",
    "\n",
    "    row_indices = np.arange(0, oh*ow).reshape(oh, -1)[::win_h, ::win_w]\n",
    "    row_indices = row_indices.reshape(1, -1)[0, :]\n",
    "    image = mat[:, row_indices, :].reshape(batch_size, 4, channels, win_h*win_w)\n",
    "    image = image.transpose(0, 2, 1, 3)\n",
    "    image = image.reshape(batch_size, channels, h//win_h, w//win_w, win_h, win_w)\n",
    "    image = image.transpose(0, 1, 2, 4, 3, 5).reshape(batch_size, channels, h, w)\n",
    "\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
