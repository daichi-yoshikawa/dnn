{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authors: Daichi Yoshikawa <daichi.yoshikawa@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from .loss_function import LossFunctionFactory\n",
    "from .loss_function import MultinomialCrossEntropy\n",
    "from .loss_function import BinomialCrossEntropy\n",
    "from .loss_function import SquaredError\n",
    "from ..utils.nn_utils import shuffle_data\n",
    "from ..utils.debug_utils import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BackPropagation:\n",
    "    \"\"\"Back propagation algorithm to update weights of neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : int\n",
    "        Number of all data scanning.\n",
    "    batch_size : int\n",
    "        Mini batch size.\n",
    "        This number of data are treated at the same time for one update of weight.\n",
    "    optimizer : Derived class of Optimizer\n",
    "            Instance of derived class of Optimizer.\n",
    "    optimizers : OrderedDict of derived class of Optimizer\n",
    "        Optimizers to update weights based on error.\n",
    "        These are created only for layer,\n",
    "        which has weight parameter, like affine layer.\n",
    "    loss_function : Derived class of LossFunction\n",
    "        Used to calculate loss.\n",
    "    monitor : Monitor\n",
    "        Used to display evaluation results.\n",
    "    dtype : type\n",
    "        Data type of variables. Generally float64 or float32.\n",
    "    \"\"\"\n",
    "    def __init__(self, epochs, batch_size, optimizer, loss_function, monitor, dtype):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        epochs : int\n",
    "            Number of all data scanning.\n",
    "        batch_size : int\n",
    "            Mini batch size.\n",
    "            This number of data are treated at the same time for one update of weight .\n",
    "        optimizer : Derived class of Optimizer\n",
    "            Instance of derived class of Optimizer.\n",
    "        loss_function : LossFunction.Type\n",
    "            Type of loss function.\n",
    "            Generally, cross entropy is used for classification and\n",
    "            squared error is used for regression.\n",
    "        monitor : bool\n",
    "            If true, display intermediate results of training.\n",
    "        dtype : type\n",
    "            Data type of variables. Generally float64 or float32.\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizers = OrderedDict()\n",
    "        self.loss_function = LossFunctionFactory.get(loss_function=loss_function)\n",
    "        self.monitor = Monitor() if monitor else None\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self, layers, x_train, y_train, x_test, y_test, shuffle_per_epoch):\n",
    "        \"\"\"Train prediction model based on training data.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configure neural network.\n",
    "        x_train : np.array\n",
    "            Descriptive features in 2d array, which is used to train model.\n",
    "            x_train.shape == (num of data, num of feature)\n",
    "        y_train : np.array\n",
    "            Target features in 2d array, which is used to train model.\n",
    "            y_train.shape == (num of data, num of feature)\n",
    "        x_test : np.array\n",
    "            Descriptive features in 2d array, which is used to evaluate model.\n",
    "            x_test.shape == x_train.shape\n",
    "        y_test : np.array\n",
    "            Target features in 2d array, which is used to evaluate model.\n",
    "            y_test.shape == y_train.shape\n",
    "        shuffle_per_epoch : bool\n",
    "            If true, shuffle training data per each epoch.\n",
    "        \"\"\"\n",
    "        self.__initialize_optimizers(layers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if shuffle_per_epoch:\n",
    "                x_train, y_train = shuffle_data(x_train, y_train)\n",
    "\n",
    "            self.__train_one_epoch(layers, x_train, y_train)\n",
    "            self.__evaluate(layers, x_train, y_train, x_test, y_test, epoch)\n",
    "\n",
    "        self.__finalize_training(layers, x_train)\n",
    "\n",
    "        y_pred = layers[0].predict(x_train)\n",
    "        consistency = np.argmax(y_train, axis=1) == np.argmax(y_pred, axis=1)\n",
    "        print(consistency.sum().astype(self.dtype) / consistency.shape[0])\n",
    "\n",
    "        y_pred = layers[0].predict(x_test)\n",
    "        consistency = np.argmax(y_test, axis=1) == np.argmax(y_pred, axis=1)\n",
    "        print(consistency.sum().astype(self.dtype) / consistency.shape[0])\n",
    "\n",
    "    def __finalize_training(self, layers, x):\n",
    "        \"\"\"This method is called after completion of training.\n",
    "\n",
    "        Optimizer or layer might require some finilization after training.\n",
    "        For example, batch normalization requires average and variance of each features\n",
    "        over all data set. This kind of procedure can be done through this method.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configure neural network.\n",
    "        x : np.array\n",
    "            Descriptive features in 2d array.\n",
    "            x_train.shape == (num of data, num of feature)\n",
    "        \"\"\"\n",
    "        layers[0].finalize_training(x)\n",
    "\n",
    "    def __train_one_epoch(self, layers, x_train, y_train):\n",
    "        \"\"\"Implements training for one epoch.\n",
    "\n",
    "        In one epoch, data is splitted into multiple bathes based on\n",
    "        batch size. Weights are updated per a batch.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configures of neural network.\n",
    "        x_train : np.array\n",
    "            Descriptive features in 2d array, which is used to train model.\n",
    "            x_train.shape == (num of data, num of feature)\n",
    "        y_train : np.array\n",
    "            Target features in 2d array, which is used to train model.\n",
    "            y_train.shape == (num of data, num of feature)\n",
    "        \"\"\"\n",
    "        data_num = x_train.shape[0]\n",
    "\n",
    "        for i in range(0, data_num, self.batch_size):\n",
    "            end = i + self.batch_size\n",
    "\n",
    "            if end > data_num:\n",
    "                end = data_num\n",
    "\n",
    "            self.__train_one_batch(layers, x_train[i:end,:], y_train[i:end,:])\n",
    "\n",
    "    def __train_one_batch(self, layers, x_train, y_train):\n",
    "        \"\"\"Implements one update of weights of neural network.\n",
    "\n",
    "        In order to update weights, forward calculation is needed firstly.\n",
    "        With the resulting forward output, backward calculation is done.\n",
    "        And then, update weights based on propagated errors in each layers.\n",
    "        The update behaves differently depending on optimizer you use.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configure neural network.\n",
    "        x_train : np.array\n",
    "            Descriptive features in 2d array, which is used to train model.\n",
    "            x_train.shape == (num of data, num of feature)\n",
    "        y_train : np.array\n",
    "            Target features in 2d array, which is used to train model.\n",
    "            y_train.shape == (num of data, num of feature)\n",
    "        \"\"\"\n",
    "        layers[0].forward(x_train)\n",
    "        layers[-1].backward(layers[-1].fire - y_train)\n",
    "        self.__optimize_network(layers)\n",
    "\n",
    "    def __initialize_optimizers(self, layers):\n",
    "        \"\"\"Create instances of optimizer for each layer which has weights in it.\n",
    "\n",
    "        Optimizer is required to update weights of neural network.\n",
    "        Since optimizer sometimes has to store some parameters for each layer,\n",
    "        each layer is supposed to be each optimizer's instance.\n",
    "        Also, layer which doesn't have weights shouldn't have optimizer.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configure neural network.\n",
    "        \"\"\"\n",
    "        self.optimizers = OrderedDict()\n",
    "\n",
    "        for i, layer in enumerate(layers, 1):\n",
    "            if layer.has_weight() is True:\n",
    "                self.optimizers[i] = copy.deepcopy(self.optimizer)\n",
    "\n",
    "    def __optimize_network(self, layers):\n",
    "        \"\"\"Update weights by optimizers.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configure neural network.\n",
    "        \"\"\"\n",
    "        for i, layer in enumerate(layers, 1):\n",
    "            if layer.has_weight() is True:\n",
    "                self.optimizers[i].optimize(layer.w, layer.dw)\n",
    "\n",
    "    def __evaluate(self, layers, x_train, y_train, x_test, y_test, epoch):\n",
    "        \"\"\"Evaluate loss of model under training.\n",
    "\n",
    "        If test data is empty, doesn't display loss w.r.t test data.\n",
    "        If you select squared error as loss function, accuracy will not displayed.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        layers : list or np.array of Layer\n",
    "            All layers which configures of neural network.\n",
    "        x_train : np.array\n",
    "            Descriptive features in 2d array, which is used to train model.\n",
    "            x_train.shape == (num of data, num of feature)\n",
    "        y_train : np.array\n",
    "            Target features in 2d array, which is used to train model.\n",
    "            y_train.shape == (num of data, num of feature)\n",
    "        x_test : np.array\n",
    "            Descriptive features in 2d array, which is used to evaluate model.\n",
    "            x_test.shape == x_train.shape\n",
    "        y_test : np.array\n",
    "            Target features in 2d array, which is used to evaluate model.\n",
    "            y_test.shape == y_train.shape\n",
    "        epoch : int\n",
    "            Number of epoch.\n",
    "        \"\"\"\n",
    "        y_test_pred = None\n",
    "        loss_test = None\n",
    "        acc_train = None\n",
    "        acc_test = None\n",
    "\n",
    "        y_train_pred = layers[0].predict_to_eval(x_train)\n",
    "        loss_train = self.loss_function.get(y=y_train_pred, t=y_train)\n",
    "\n",
    "        if x_test.size != 0:\n",
    "            y_test_pred = layers[0].predict_to_eval(x_test)\n",
    "            loss_test = self.loss_function.get(y=y_test_pred, t=y_test)\n",
    "\n",
    "        if self.loss_function is not SquaredError:\n",
    "            acc_train = self.__get_accuracy(y=y_train, y_pred=y_train_pred)\n",
    "\n",
    "            if y_test_pred.size != 0:\n",
    "                acc_test = self.__get_accuracy(y=y_test, y_pred=y_test_pred)\n",
    "\n",
    "        if self.monitor is not None:\n",
    "            self.monitor.print_loss(loss_train, loss_test, acc_train, acc_test, epoch)\n",
    "\n",
    "    def __get_accuracy(self, y, y_pred):\n",
    "        \"\"\"Calculate accuracy and return it.\n",
    "\n",
    "        This method is supposed to be called only in the case of classification.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array\n",
    "            Reference of target features in 2d array.\n",
    "            y.shape == (num of data, num of feature)\n",
    "        y_pred : np.array\n",
    "            Predicted target features in 2d array.\n",
    "            y_pred.shape == (num of data, num of feature)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Accuracy of predicted result in range from 0.0 to 1.0.\n",
    "        \"\"\"\n",
    "        consistency = np.argmax(y, axis=1) == np.argmax(y_pred, axis=1)\n",
    "        return consistency.sum().astype(self.dtype) / consistency.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
