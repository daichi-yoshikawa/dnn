{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Authors: Daichi Yoshikawa <daichi.yoshikawa@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import dnn\n",
    "from dnn.neuralnet import NeuralNetwork\n",
    "from dnn.utils.nn_utils import scale_normalization\n",
    "\n",
    "from dnn.training.optimizer import Adam, AdaGrad, AdaDelta, Momentum\n",
    "from dnn.training.random_weight import RandomWeight\n",
    "from dnn.training.loss_function import LossFunction\n",
    "\n",
    "from dnn.layers.layer import InputLayer, OutputLayer\n",
    "from dnn.layers.affine import AffineLayer\n",
    "\n",
    "from dnn.layers.activation import Activation, ActivationLayer\n",
    "from dnn.layers.dropout import DropoutLayer\n",
    "from dnn.layers.batch_norm import BatchNormLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    x = np.load('input1.npy')\n",
    "    x = np.r_[x, np.load('input2.npy')]\n",
    "    x = np.r_[x, np.load('input3.npy')]\n",
    "    x = np.r_[x, np.load('input4.npy')]\n",
    "    x = np.r_[x, np.load('input5.npy')]\n",
    "    x = np.r_[x, np.load('input6.npy')]\n",
    "    x = np.r_[x, np.load('input7.npy')]\n",
    "    x = x.astype(float)\n",
    "    \n",
    "    y = np.load('output.npy')\n",
    "    y = y.astype(float)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    1, loss: 0.137337, acc: 0.959,                  test loss: 0.142824, test acc: 0.956\n",
      "epoch:    2, loss: 0.101247, acc: 0.969,                  test loss: 0.111148, test acc: 0.965\n",
      "epoch:    3, loss: 0.086201, acc: 0.974,                  test loss: 0.099936, test acc: 0.970\n",
      "epoch:    4, loss: 0.075493, acc: 0.977,                  test loss: 0.090839, test acc: 0.972\n",
      "epoch:    5, loss: 0.068240, acc: 0.979,                  test loss: 0.085673, test acc: 0.973\n",
      "epoch:    6, loss: 0.063756, acc: 0.981,                  test loss: 0.083488, test acc: 0.974\n",
      "epoch:    7, loss: 0.059852, acc: 0.981,                  test loss: 0.080317, test acc: 0.976\n",
      "epoch:    8, loss: 0.053103, acc: 0.984,                  test loss: 0.073446, test acc: 0.977\n",
      "epoch:    9, loss: 0.050596, acc: 0.985,                  test loss: 0.070005, test acc: 0.977\n",
      "epoch:   10, loss: 0.047982, acc: 0.986,                  test loss: 0.070688, test acc: 0.978\n",
      "epoch:   11, loss: 0.046030, acc: 0.986,                  test loss: 0.070778, test acc: 0.977\n",
      "epoch:   12, loss: 0.043604, acc: 0.987,                  test loss: 0.068061, test acc: 0.978\n",
      "epoch:   13, loss: 0.041769, acc: 0.987,                  test loss: 0.066075, test acc: 0.978\n",
      "epoch:   14, loss: 0.039340, acc: 0.988,                  test loss: 0.063901, test acc: 0.980\n",
      "epoch:   15, loss: 0.037643, acc: 0.988,                  test loss: 0.062367, test acc: 0.980\n",
      "0.988466666667\n",
      "0.9795\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float32\n",
    "neuralnet = NeuralNetwork(dtype=dtype)\n",
    "neuralnet.add(InputLayer(shape=784))\n",
    "neuralnet.add(DropoutLayer(drop_ratio=0.2))\n",
    "neuralnet.add(AffineLayer(shape=(784, 200), random_weight=RandomWeight.Type.he))\n",
    "neuralnet.add(BatchNormLayer())\n",
    "neuralnet.add(ActivationLayer(activation=Activation.Type.relu))\n",
    "neuralnet.add(DropoutLayer(drop_ratio=0.5))\n",
    "neuralnet.add(AffineLayer(shape=(200, 10), random_weight=RandomWeight.Type.xavier))\n",
    "neuralnet.add(BatchNormLayer())\n",
    "neuralnet.add(ActivationLayer(activation=Activation.Type.softmax))\n",
    "neuralnet.add(OutputLayer(shape=10))\n",
    "neuralnet.compile()\n",
    "\n",
    "x, y = get_mnist()\n",
    "scale_normalization(x)\n",
    "\n",
    "optimizer = AdaGrad(learning_rate=3e-2, weight_decay=1e-3, dtype=dtype)\n",
    "\n",
    "neuralnet.fit(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        epochs=15,\n",
    "        batch_size=100,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=LossFunction.Type.multinomial_cross_entropy,\n",
    "        monitor=True,\n",
    "        shuffle=True,\n",
    "        shuffle_per_epoch=True,\n",
    "        test_data_ratio=0.142857\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
